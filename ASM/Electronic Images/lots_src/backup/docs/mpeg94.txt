
                   MPEG Video Playback in Software
                 (Summary submitted to IS&T/SPIE '94)
                           (July 9, 1993)

         Lawrence A. Rowe, Ketan Patel, Brian C. Smith, Kim Liu
                   Computer Science Division - EECS
                       University of California
                          Berkeley, CA 94720
              (phone: 510-642-5117, fax: 510-642-5615)
                     (email:rowe@CS.Berkeley.EDU)


This paper describes the design and implementation of a continuous 
media playback system that supports software decoding of MPEG video 
streams. The system supports full-function playback (i.e., forward and 
backward play at variable speeds and random positioning) of data stored on a 
file server (i.e., network delivery). The software mechanisms described 
include: 1) CPU scheduling to meet real-time constraints, 2) heuristics 
to select which frames to deliver given limited CPU and network bandwidth 
resources, and 3) the file representation of MPEG bit streams to support 
playback. This paper describes the video stream data representation and 
the mechanisms required to support full-function playback. 

We previously developed and published an MPEG video software decoder [1, 2] 
and a continuous media playback system, called the CMPlayer [3]. The decoder 
reads video data from a file and decodes, dithers, and displays the frames 
as fast as possible. However, frames are played when decoded, not when they 
are required, and synchronized audio is not supported.

The CMPlayer is a portable playback system for delivery of continuous 
media data over networks. The system supports synchronized playback of 
video and audio streams stored on a file server. Source and destination 
objects are created for each stream-type linked by a data delivery protocol. 
Synchronization between the source and destination processes is 
controlled through a distributed logical time system object. The CMPlayer 
plays scripts which are files that describe how clips of continuous media 
data, stored separately in a clip file, are composed into streams and 
synchronized. Currently, the CMPlayer supports a motion-JPEG video stream 
using a hardware CODEC and a SPARC audio stream. The system uses TCP/IP 
network communication. It has been run on a conventional Ethernet and on 
faster FDDI networks.

This paper describes the integration of the MPEG video software decoder 
into the CMPlayer. Several problems were solved. First, the data 
representation of an MPEG video stream was modified to provide additional 
information. The clip file representation of an MPEG video stream contains 
three parts: 1) a header, 2) the MPEG stream, and 3) indexes. The header 
contains a standard clip file header that contains basic information 
required by the CMPlayer such as the stream type (i.e. MPEG video), width, 
height, playback rate, maximum frame size, and the offset to the index data. 
The MPEG stream is a standard MPEG video bit stream including headers 
(e.g., group of picture, slice, etc.). The indexes at the end of the 
file contain information about frames (e.g., file offset, reference frame 
dependencies, size, and system header dependencies) that simplify the 
playback algorithm. The header and indexes are derived from an MPEG bit 
stream when it is loaded into the system.

The second problem that had to be solved was efficient utilization 
of resources given that frames must be dropped. Frames are dropped because 
there is not enough time to decode all frames on the destination processor, 
because network constraints limit the number of frames that can be transmitted,
and because the user is playing the script either slower or faster than 
real-time. Dropping frames is harder with MPEG because decoding P- and 
B-frames requires the data from other frames. Frames are easier to drop 
in the motion-JPEG stream because there is no inter-frame compression.

The runtime mechanisms are implemented in the sending process, called 
the continuous media source (CMS), and the destination process, 
called the continuous media server for X (CMX). The CMS sends frames 
before they are required to smooth out network latencies. CMS keeps track of
the frames already sent and only sends a frame if the required dependency 
frames have already been received. CMX incrementally decodes and dithers 
the frame. Before doing the next increment, it estimates the time required 
to complete the frame. If it cannot be completed before the time the 
frame must be played, it might be dropped. However, the frame will not 
be dropped if the completion time is estimated to be before the time 
decoding must start for the next frame to be played. This heuristic is 
required so that the player will not partially decode a series of frames and 
never display any of them because it always runs out of time to finish 
the decoding. In addition, the system prioritizes which frames to drop. 
Dropping a reference frame (e.g., an I- or P-frame) causes more frames to 
be dropped than a B-frame. Consequently, the system drops B-frames, but 
resists the temptation to drop I- and P-frames. These heuristics are 
complex because the system wants to play the maximum number of frames 
possible and minimize the standard deviation of the time between frames 
being played. Finally, since the delivery of data is not guaranteed and may 
occur out of order, mechanisms for reordering frames is necessary.

The full paper will describe these mechanisms in more detail and 
present data to demonstrate how well they work.


REFERENCES

1. Patel, Ketan and Lawrence A. Rowe, Brian C. Smith, "Performance of 
a Software MPEG Video Decoder," Proceedings ACM Multimedia `93, 
Anaheim CA (Aug. 1993).

2. ISO/IEC JTC/SC29, "Coded Representation of Picture, Audio and 
Multimedia/Hypermedia Information", Committee Draft of Standard 
ISO/IEC 11172, December 6, 1991.

3. Rowe, Lawrence A. and Brian C. Smith,  "A Continuous Media Player,"     
Proceedings. 3rd Int'l Workshop on Network and Operating System Support 
for Digital Audio and Video, San Diego, CA (Nov. 1992).
