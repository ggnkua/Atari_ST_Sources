.TH ols Local "24 May 1991"
.SH NAME
ols \- Estimate linear regressions.
.SH SYNOPSIS
.B ols 
[\-\fIh\fR\|]
[\-\fIp\fR\|]
[\-\fIraw\fR\|]
[\-\fIl\fR labelstring\|]
[\-\fIm\fR model_spec \|]
[\-\fIepp\|]
[inputfilename]
.SH DESCRIPTION
\fIols\fR takes a set of observations from the specified input file.
There must be exactly one observation per line.  
If no input file is specified, \fIols\fR reads data from 
Standard Input.
.PP
How is this input file organised?  All lines must have the
same layout of variables (fields), and the same number of variables.
Given a set of variables in a data file, you can run any
regression which uses some (but not necessarily all) of these
variables as l.h.s. or r.h.s. variable(s).
.PP
Defining the layout of the input lines and choosing r.h.s. and
l.h.s. variables "by hand" is slightly tedious.
\fIols\fR offers a default behaviour which might be useful.
In the event that you do not choose l.h.s. and r.h.s. variables
yourself, it assumes you want a regression as follows: the last
(rightmost) variable on each line is considered to be the l.h.s.
variable and all other variables are used as r.h.s. regressors.
.PP
.SH The Intercept
.br
.I ols
knows nothing about the intercept of the regression line.  By
default, there is
.B no
intercept.  If you want an intercept, you must include a variable
in the dataset which always takes the value 1.0.  This is
readily done using Unix tools like
\fIawk\fR(1) or \fIsed\fR(1).

Notice that omitting the intercept implies \fIforcing\fR the
regression line to pass through the origin.  If this restriction
is forced unintentionally, it will almost certainly lead to
nonsensical results.  Make sure you have a good reason for
wanting to impose such a restriction, and be aware that
.I ols
will implicitly impose this restriction if you do not include
a r.h.s. regressor which always takes the value 1.
.PP
.SH OPTIONS
.TP
.B \-h
This option gives some minimal quickstart help.  All other 
arguments are ignored if it is found.
.TP
.B \-l labelstring
This option allows you to attach variable names to your variables.
Thus, if you have three numbers per line in a regression of 
\fIy\fR on \fIx\fR with an intercept, you could use a 
labelstring of the form 'constant x y'.  
.br
The labels do several things.  They help in the pretty printing
of the regression results.  When the \fB-p\fR switch is used, the
labels enable a more readable generated awk script.  Finally,
labels are essential when specifying a model different from the
default model (using the \fB-m\fR switch).
.br
If no labels are specified, \fIols\fR
invents variable names of the form \fB$n\fR for use in printing
the results.  Similar defaults are used in the generated awk
code.
.br
The individual labels must be delimited by whitespace (spaces or
tabs).  Note that you should quote labelstring to make sure shell
treats the labels as one argument.
.TP
.B \-m model_spec
This option allows you to specify a model different from the
default.  Suppose the labelstring is '_one x y z'.  The default
model being estimated is z = f(_one, x, y).  If you want to
estimate a model y = f(_one z), you would use the flags
\fB-m 'y = _one z'\fR.
.TP
.B \-p
This option disables the display of regression results.
Instead, \fIols\fR prints a \fIawk\fR(1) program on Standard
Output.  This awk program does prediction using the estimated
regression model.
.br
The generated awk code is indented and commented.  This is
because there are situations where the most convenient way to execute
a task is to use \fIols\fR to do the estimation, and modify the
generated awk code to fit the job at hand.
.br
The generated awk code works with either of \fIawk\fR(1) or \fInawk\fR(1).
.TP
.B \-raw
The 
\fB\-raw\fR
option produces a highly truncated output.  Instead of the full
regressions results, 
.I ols
merely produces one line on Standard Output: all the regression
coefficients followed by the regression standard error.
.TP
.B \-epp
This option disables the normal display of regression results.
Instead, \fIols\fR prints the results of estimation in a form
more suited to post-processing.  A post-processor which converts this
into a LaTeX table (called \fIepp2tex\fR) is shipped with 
\fIols\fR.  See the example below.
.SH EXAMPLES
You can get started without much fuss:

     ols < data.1k

estimates a regression using data in the file 'data.1k', using
the default choice of l.h.s. and r.h.s. variable(s).

An example of integration with awk on input:

     awk '{print "1 " $0}' data.text  |  ols -l 'cons x y'

Here, the file data.text contains observations which are (x, y)
points.  By default \fIols\fR
estimates regressions without an intercept.  So we use 
\fIawk\fR(1) to add in the vector of 1s.  The \fB-l\fR is used 
to describe the layout of the input lines: 1.0, x and y.

An example of using generated awk code:

    ols -p data.est > a.awk

    awk -f a.awk data.est > insample.predictions

    awk -f a.awk data.osp > outofsample.predictions

Here, the \fB-p\fR flag is used to get \fIols\fR to produce an awk
program which does prediction.  This program is applied to the
estimation dataset data.est to get insample predictions, and to
a different file (data.osp) to get out-of-sample predictions.

The \fB-epp\fR flag is used for getting results in a form
suitable for post-processing.  The program \fIepp2tex.nawk\fR is
shipped with \fIols\fR.  Thus you could say

    ols -epp -l '_one x y z' -m 'z = _one x' datafile | nawk -f epp2tex.nawk > a.tex

Lookup the \fIepp2tex\fR documentation for details on switches recognised
by it.
.SH NOTES
This is version 1.0.
.PP
The biggest dataset usable is somewhat smaller than swap space.
The amount of memory consumed is exactly what the dataset
calls for.
.PP
There are no hard limits on either the number of r.h.s. variables 
or the number of observations.
.SH BUGS
It doesn't know about missing data.  Fixing this is not on the
cards.

If you do an estimation with seemingly straightforward data, and
get blatantly nonsensical estimates, then it's possible that
you have a linear dependence among the r.h.s. variables.  Try
this dataset on \fIols\fR for an example:

    1 1 1 2

    1 2 2 7

    1 5 5 3

    1 4 4 19

\fIols\fR is very low on intelligence in sensing such degenerate 
multicollinearity.  This will be remedied in the next version.

.SH AUTHOR
Ajay Shah, Rand Corporation, Santa Monica, CA
.br
Ajay_Shah@rand.org

